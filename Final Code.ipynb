{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon_0103_revised.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5fzzSHbhQoST",
        "_Ly9h3GZa-uB",
        "i9iB3FpabF9D",
        "PFdhLuy7blDD",
        "TPO9UfKLcA32",
        "QUYirKpkcIFN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJplHM00P139"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08CzTavkWiGl",
        "outputId": "47ea2aea-6d54-467a-bc9b-ebe10af90ce7"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC_Hf4kHQA2m"
      },
      "source": [
        "import pandas as pd\r\n",
        "train = pd.read_csv(\"drive/My Drive/open/news_train.csv\",encoding='utf-8-sig')\r\n",
        "test = pd.read_csv(\"drive/My Drive/open/news_test.csv\",encoding='utf-8-sig')\r\n",
        "sample_submission =pd.read_csv('drive/My Drive/open/sample_submission.csv',encoding='utf-8-sig')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fzzSHbhQoST"
      },
      "source": [
        "# Library 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXU2R19mQk_H",
        "outputId": "f2611ad9-6455-47b2-f66f-d05835e96dd3"
      },
      "source": [
        "!pip install fasttext\r\n",
        "import fasttext"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 28.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (51.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.19.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3041379 sha256=043ac67dc440a5dcd4359494ab0c74b608b9cbc31d55e81ebf09d3f9d97ee485\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbyXuUR7QuOb",
        "outputId": "61ca030f-e4d5-4997-caae-f5987a3384e1"
      },
      "source": [
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 75 (delta 33), reused 20 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6Dpm1yQQwUw",
        "outputId": "0be64ef4-7393-4eaf-d4b9-a608bc853900"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP_fEt8dQx1E",
        "outputId": "6536b7d7-9a5f-4933-9f8e-bc4047d44f8d"
      },
      "source": [
        "! bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.8MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, tweepy, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-01-03 06:23:17--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.0, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=L7AV074T0mmr1oZYkA7OY2rCqNo%3D&Expires=1609656707&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-01-03 06:23:17--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=L7AV074T0mmr1oZYkA7OY2rCqNo%3D&Expires=1609656707&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.77.92\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.77.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-01-03 06:23:17 (37.6 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-01-03 06:24:31--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22c5:2ef4, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=1I6cpauYsvyXPjKY7Wq4rwvNRhQ%3D&Expires=1609656786&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-01-03 06:24:31--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=1I6cpauYsvyXPjKY7Wq4rwvNRhQ%3D&Expires=1609656786&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.94.92\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.94.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   117MB/s    in 0.4s    \n",
            "\n",
            "2021-01-03 06:24:32 (117 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd3_RmwLQ-9N",
        "outputId": "8833f229-5954-4f3b-9f45-404f64fc1f47"
      },
      "source": [
        "!wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-03 06:25:37--  https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/facebookresearch/fastText/zip/v0.9.2 [following]\n",
            "--2021-01-03 06:25:37--  https://codeload.github.com/facebookresearch/fastText/zip/v0.9.2\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘v0.9.2.zip’\n",
            "\n",
            "v0.9.2.zip              [  <=>               ]   4.17M  17.5MB/s    in 0.2s    \n",
            "\n",
            "2021-01-03 06:25:38 (17.5 MB/s) - ‘v0.9.2.zip’ saved [4369852]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KkVgE5gRQ6D",
        "outputId": "c1e7f846-4ea2-4d68-e0a5-9b0d5d9e451f"
      },
      "source": [
        "!unzip v0.9.2.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  v0.9.2.zip\n",
            "5b5943c118b0ec5fb9cd8d20587de2b2d3966dfe\n",
            "   creating: fastText-0.9.2/\n",
            "   creating: fastText-0.9.2/.circleci/\n",
            "  inflating: fastText-0.9.2/.circleci/cmake_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/config.yml  \n",
            "  inflating: fastText-0.9.2/.circleci/gcc_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/pip_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/pull_data.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/python_test.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/run_locally.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/setup_circleimg.sh  \n",
            "  inflating: fastText-0.9.2/.circleci/setup_debian.sh  \n",
            "  inflating: fastText-0.9.2/.gitignore  \n",
            "  inflating: fastText-0.9.2/CMakeLists.txt  \n",
            "  inflating: fastText-0.9.2/CODE_OF_CONDUCT.md  \n",
            "  inflating: fastText-0.9.2/CONTRIBUTING.md  \n",
            "  inflating: fastText-0.9.2/LICENSE  \n",
            "  inflating: fastText-0.9.2/MANIFEST.in  \n",
            "  inflating: fastText-0.9.2/Makefile  \n",
            "  inflating: fastText-0.9.2/README.md  \n",
            "   creating: fastText-0.9.2/alignment/\n",
            "  inflating: fastText-0.9.2/alignment/README.md  \n",
            "  inflating: fastText-0.9.2/alignment/align.py  \n",
            "  inflating: fastText-0.9.2/alignment/eval.py  \n",
            "  inflating: fastText-0.9.2/alignment/example.sh  \n",
            "  inflating: fastText-0.9.2/alignment/unsup_align.py  \n",
            "  inflating: fastText-0.9.2/alignment/unsup_multialign.py  \n",
            "  inflating: fastText-0.9.2/alignment/utils.py  \n",
            "  inflating: fastText-0.9.2/classification-example.sh  \n",
            "  inflating: fastText-0.9.2/classification-results.sh  \n",
            "   creating: fastText-0.9.2/crawl/\n",
            "  inflating: fastText-0.9.2/crawl/README.md  \n",
            "  inflating: fastText-0.9.2/crawl/dedup.cc  \n",
            "  inflating: fastText-0.9.2/crawl/download_crawl.sh  \n",
            "  inflating: fastText-0.9.2/crawl/filter_dedup.sh  \n",
            "  inflating: fastText-0.9.2/crawl/filter_utf8.cc  \n",
            "  inflating: fastText-0.9.2/crawl/process_wet_file.sh  \n",
            "   creating: fastText-0.9.2/docs/\n",
            "  inflating: fastText-0.9.2/docs/aligned-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/api.md  \n",
            "  inflating: fastText-0.9.2/docs/autotune.md  \n",
            "  inflating: fastText-0.9.2/docs/cheatsheet.md  \n",
            "  inflating: fastText-0.9.2/docs/crawl-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/dataset.md  \n",
            "  inflating: fastText-0.9.2/docs/english-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/faqs.md  \n",
            "  inflating: fastText-0.9.2/docs/language-identification.md  \n",
            "  inflating: fastText-0.9.2/docs/options.md  \n",
            "  inflating: fastText-0.9.2/docs/pretrained-vectors.md  \n",
            "  inflating: fastText-0.9.2/docs/python-module.md  \n",
            "  inflating: fastText-0.9.2/docs/references.md  \n",
            "  inflating: fastText-0.9.2/docs/supervised-models.md  \n",
            "  inflating: fastText-0.9.2/docs/supervised-tutorial.md  \n",
            "  inflating: fastText-0.9.2/docs/support.md  \n",
            "  inflating: fastText-0.9.2/docs/unsupervised-tutorials.md  \n",
            "  inflating: fastText-0.9.2/docs/webassembly-module.md  \n",
            "  inflating: fastText-0.9.2/download_model.py  \n",
            "  inflating: fastText-0.9.2/eval.py  \n",
            "  inflating: fastText-0.9.2/fasttext.pc.in  \n",
            "  inflating: fastText-0.9.2/get-wikimedia.sh  \n",
            "   creating: fastText-0.9.2/python/\n",
            "  inflating: fastText-0.9.2/python/README.md  \n",
            "  inflating: fastText-0.9.2/python/README.rst  \n",
            "   creating: fastText-0.9.2/python/benchmarks/\n",
            "  inflating: fastText-0.9.2/python/benchmarks/README.rst  \n",
            "  inflating: fastText-0.9.2/python/benchmarks/get_word_vector.py  \n",
            "   creating: fastText-0.9.2/python/doc/\n",
            "   creating: fastText-0.9.2/python/doc/examples/\n",
            "  inflating: fastText-0.9.2/python/doc/examples/FastTextEmbeddingBag.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/bin_to_vec.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/compute_accuracy.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/get_vocab.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/train_supervised.py  \n",
            "  inflating: fastText-0.9.2/python/doc/examples/train_unsupervised.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/\n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/FastText.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/__init__.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/pybind/fasttext_pybind.cc  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/tests/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/__init__.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_configurations.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/tests/test_script.py  \n",
            "   creating: fastText-0.9.2/python/fasttext_module/fasttext/util/\n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/__init__.py  \n",
            "  inflating: fastText-0.9.2/python/fasttext_module/fasttext/util/util.py  \n",
            "  inflating: fastText-0.9.2/quantization-example.sh  \n",
            "  inflating: fastText-0.9.2/reduce_model.py  \n",
            "  inflating: fastText-0.9.2/runtests.py  \n",
            "   creating: fastText-0.9.2/scripts/\n",
            "   creating: fastText-0.9.2/scripts/kbcompletion/\n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/README.md  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/data.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/eval.cpp  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/fb15k237.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/svo.sh  \n",
            "  inflating: fastText-0.9.2/scripts/kbcompletion/wn18.sh  \n",
            "   creating: fastText-0.9.2/scripts/quantization/\n",
            "  inflating: fastText-0.9.2/scripts/quantization/quantization-results.sh  \n",
            " extracting: fastText-0.9.2/setup.cfg  \n",
            "  inflating: fastText-0.9.2/setup.py  \n",
            "   creating: fastText-0.9.2/src/\n",
            "  inflating: fastText-0.9.2/src/args.cc  \n",
            "  inflating: fastText-0.9.2/src/args.h  \n",
            "  inflating: fastText-0.9.2/src/autotune.cc  \n",
            "  inflating: fastText-0.9.2/src/autotune.h  \n",
            "  inflating: fastText-0.9.2/src/densematrix.cc  \n",
            "  inflating: fastText-0.9.2/src/densematrix.h  \n",
            "  inflating: fastText-0.9.2/src/dictionary.cc  \n",
            "  inflating: fastText-0.9.2/src/dictionary.h  \n",
            "  inflating: fastText-0.9.2/src/fasttext.cc  \n",
            "  inflating: fastText-0.9.2/src/fasttext.h  \n",
            "  inflating: fastText-0.9.2/src/loss.cc  \n",
            "  inflating: fastText-0.9.2/src/loss.h  \n",
            "  inflating: fastText-0.9.2/src/main.cc  \n",
            "  inflating: fastText-0.9.2/src/matrix.cc  \n",
            "  inflating: fastText-0.9.2/src/matrix.h  \n",
            "  inflating: fastText-0.9.2/src/meter.cc  \n",
            "  inflating: fastText-0.9.2/src/meter.h  \n",
            "  inflating: fastText-0.9.2/src/model.cc  \n",
            "  inflating: fastText-0.9.2/src/model.h  \n",
            "  inflating: fastText-0.9.2/src/productquantizer.cc  \n",
            "  inflating: fastText-0.9.2/src/productquantizer.h  \n",
            "  inflating: fastText-0.9.2/src/quantmatrix.cc  \n",
            "  inflating: fastText-0.9.2/src/quantmatrix.h  \n",
            "  inflating: fastText-0.9.2/src/real.h  \n",
            "  inflating: fastText-0.9.2/src/utils.cc  \n",
            "  inflating: fastText-0.9.2/src/utils.h  \n",
            "  inflating: fastText-0.9.2/src/vector.cc  \n",
            "  inflating: fastText-0.9.2/src/vector.h  \n",
            "   creating: fastText-0.9.2/tests/\n",
            "  inflating: fastText-0.9.2/tests/fetch_test_data.sh  \n",
            "   creating: fastText-0.9.2/webassembly/\n",
            "  inflating: fastText-0.9.2/webassembly/README.md  \n",
            "   creating: fastText-0.9.2/webassembly/doc/\n",
            "   creating: fastText-0.9.2/webassembly/doc/examples/\n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/misc.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/predict.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/train_supervised.html  \n",
            "  inflating: fastText-0.9.2/webassembly/doc/examples/train_unsupervised.html  \n",
            "  inflating: fastText-0.9.2/webassembly/fasttext.js  \n",
            "  inflating: fastText-0.9.2/webassembly/fasttext_wasm.cc  \n",
            "   creating: fastText-0.9.2/website/\n",
            "  inflating: fastText-0.9.2/website/README.md  \n",
            "   creating: fastText-0.9.2/website/blog/\n",
            "  inflating: fastText-0.9.2/website/blog/2016-08-18-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2017-05-02-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2017-10-02-blog-post.md  \n",
            "  inflating: fastText-0.9.2/website/blog/2019-06-25-blog-post.md  \n",
            "   creating: fastText-0.9.2/website/core/\n",
            "  inflating: fastText-0.9.2/website/core/Footer.js  \n",
            "  inflating: fastText-0.9.2/website/package.json  \n",
            "   creating: fastText-0.9.2/website/pages/\n",
            "   creating: fastText-0.9.2/website/pages/en/\n",
            "  inflating: fastText-0.9.2/website/pages/en/index.js  \n",
            "  inflating: fastText-0.9.2/website/sidebars.json  \n",
            "  inflating: fastText-0.9.2/website/siteConfig.js  \n",
            "   creating: fastText-0.9.2/website/static/\n",
            "   creating: fastText-0.9.2/website/static/docs/\n",
            "   creating: fastText-0.9.2/website/static/docs/en/\n",
            "   creating: fastText-0.9.2/website/static/docs/en/html/\n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/.classfasttext_1_1QMatrix-members.html.i4eKqy  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/annotated_dup.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/args_8h_source.html  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/bc_s.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/bdwn.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classes.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Args.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Dictionary.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1FastText.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Matrix.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Model.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1QMatrix.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/classfasttext_1_1Vector.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/closed.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dictionary_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/doc.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/doxygen.css  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/doxygen.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/dynsections.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/fasttext_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/favicon.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/files.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/files.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/folderclosed.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/folderopen.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_0x7e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_dup.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_g.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_i.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_k.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_l.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_m.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_n.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_o.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_p.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_q.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_r.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_s.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_t.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_u.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_v.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_vars.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_w.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/functions_z.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_defs.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/globals_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/index.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/jquery.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/main_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/matrix_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/menu.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/menudata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/model_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacefasttext_1_1utils.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_enum.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_func.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespacemembers_type.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/namespaces.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/nav_f.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_g.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/nav_h.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtree.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreedata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/navtreeindex1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/open.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/productquantizer_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/qmatrix_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/real_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/resize.js  \n",
            "   creating: fastText-0.9.2/website/static/docs/en/html/search/\n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/.files_7.html.StRRNc  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/.variables_a.html.1MGQ27  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_14.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_15.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_16.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_17.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/all_f.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/classes_8.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/close.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/defines_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enums_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/enumvalues_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/files_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_14.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_15.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_16.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_17.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/functions_f.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/mag_sel.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/namespaces_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/nomatches.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_l.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/search_m.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/search/search_r.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/searchdata.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/typedefs_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_0.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_1.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_10.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_11.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_12.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_13.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_2.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_3.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_4.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_5.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_6.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_7.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_8.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_9.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_a.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_b.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_c.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_d.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_e.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/search/variables_f.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/splitbar.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1Node.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry-members.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/structfasttext_1_1entry.js  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/sync_off.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/sync_on.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_a.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_b.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_h.png  \n",
            " extracting: fastText-0.9.2/website/static/docs/en/html/tab_s.png  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/tabs.css  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/utils_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8cc.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.html  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h.js  \n",
            "  inflating: fastText-0.9.2/website/static/docs/en/html/vector_8h_source.html  \n",
            "  inflating: fastText-0.9.2/website/static/fasttext.css  \n",
            "   creating: fastText-0.9.2/website/static/img/\n",
            "   creating: fastText-0.9.2/website/static/img/authors/\n",
            "  inflating: fastText-0.9.2/website/static/img/authors/armand_joulin.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/christian_puhrsch.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/edouard_grave.jpeg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/piotr_bojanowski.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/authors/tomas_mikolov.jpg  \n",
            "   creating: fastText-0.9.2/website/static/img/blog/\n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img1.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2016-08-18-blog-post-img2.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img1.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-05-02-blog-post-img2.jpg  \n",
            "  inflating: fastText-0.9.2/website/static/img/blog/2017-10-02-blog-post-img1.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/cbo_vs_skipgram.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-api.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-bg-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-square.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-color-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-faq.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-tutorial.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-icon-white-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-color-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/fasttext-logo-white-web.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/logo-color.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-black.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-blue.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/model-red.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/ogimage.png  \n",
            "  inflating: fastText-0.9.2/website/static/img/oss_logo.png  \n",
            "  inflating: fastText-0.9.2/website/static/tabber.js  \n",
            "  inflating: fastText-0.9.2/wikifil.pl  \n",
            "  inflating: fastText-0.9.2/word-vector-example.sh  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdg-RPT7RTv3",
        "outputId": "8d73b3b2-4515-4ee9-e3de-4d933657b5ce"
      },
      "source": [
        "%cd fastText-0.9.2\r\n",
        "!make"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab/fastText-0.9.2\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n",
            "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLX5UsDsRUhM",
        "outputId": "b11b4f95-3dfc-4dfb-b8b6-9b3c7ac29e32"
      },
      "source": [
        "!pwd\r\n",
        "\r\n",
        "# Mecab 설치 폴더 내 Fasttext 폴더가 설치되어있음을 가정"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab/fastText-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwq6DvOASBv_"
      },
      "source": [
        "# 시간 측정 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF4ViT9pSDbO"
      },
      "source": [
        "import time\r\n",
        "start = time.time()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_SY3MzCRs1L"
      },
      "source": [
        "# Library 불러오기\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fJAFaIsRxC4",
        "outputId": "05b19a18-537b-4430-924d-2e8e3b7ab572"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "from collections import Counter\r\n",
        "import re\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "from konlpy.tag import Mecab \r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn import metrics, model_selection\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "import xgboost as xgb\r\n",
        "import warnings\r\n",
        "\r\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxlcuobNSrTz"
      },
      "source": [
        "## pos_Tagger, Tokenizer, pretraind_embedding, Model 불러오기\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwzOH6nI1g8I",
        "outputId": "f2720fcd-7a9b-48f5-be26-80ecc5a07f87"
      },
      "source": [
        "os.chdir('/content')\r\n",
        "!pwd # 현재 경로"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5xjNPNIRcH6"
      },
      "source": [
        "mecab = Mecab() # Pos_Tagger, Tokenizer\r\n",
        "glove = dict()\r\n",
        "\r\n",
        "# Train, Test와 동일경로에 Glove.txt가 설치되어있음을 가정\r\n",
        "f = open('drive/My Drive/open/glove.txt',encoding='utf-8')  # Pretrained_Embedding(glove)\r\n",
        "for line in f:\r\n",
        "    values = line.split()\r\n",
        "    word = values[0]\r\n",
        "    vector = np.array(values[1:101], dtype='float32') # 100차원의 사전학습 임베딩을 불러옴\r\n",
        "    glove[word] = vector # Dictionary에 저장\r\n",
        "f.close()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZorMb7ATolL"
      },
      "source": [
        "# 형태소 분석 + 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HGoh2qETgvl"
      },
      "source": [
        "# 토큰화 후 puctuation 제거\r\n",
        "def get_words(text):\r\n",
        "    words = mecab.morphs(text)\r\n",
        "    return [word for word in words if not word in string.punctuation]\r\n",
        "\r\n",
        "# 특수문자 제외한 토큰화 결과 중 첫 번째 요소 길이 출력\r\n",
        "def first_word_len(text):\r\n",
        "    if (len(text)==0):\r\n",
        "        return 0\r\n",
        "    else:   \r\n",
        "        return len(text[0])\r\n",
        "\r\n",
        "# 특수문자 제외한 토큰화 결과 중 마지막 요소 길이 출력\r\n",
        "def last_word_len(text):\r\n",
        "    if(len(text)==0):\r\n",
        "        return 0\r\n",
        "    else:   \r\n",
        "        return len(text[-1])\r\n",
        "\r\n",
        "symbols_knowns = string.ascii_letters + string.digits + string.punctuation\r\n",
        "\r\n",
        "# 특정 요소가 symbols_knows 중 어디에 위치해있는지를 출력\r\n",
        "# 첫 글자와 마지막 글자에 적용시킴\r\n",
        "def symbol_id(x):\r\n",
        "    symbols=[x for x in symbols_knowns]\r\n",
        "      \r\n",
        "    if x not in symbols:\r\n",
        "        return -1 \r\n",
        "    else:\r\n",
        "        return np.where(np.array(symbols) == x )[0][0]\r\n",
        "\r\n",
        "# 체언의 비율을 계산\r\n",
        "def fraction_noun(text):\r\n",
        "    text_splited = text.split(' ')\r\n",
        "    text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\r\n",
        "    text_splited = [s for s in text_splited if s]\r\n",
        "    word_count = text_splited.__len__()\r\n",
        "    if word_count==0:\r\n",
        "        return 0\r\n",
        "    else:\r\n",
        "        pos_list = mecab.pos(' '.join(text_splited))  # EDIT\r\n",
        "        #nn = []\r\n",
        "        noun_count = len([w for w in pos_list if w[1] in ('NNG', 'NNP', 'NNB', 'NNBC', 'NR', 'NP')])\r\n",
        "        return (noun_count/word_count)\r\n",
        "\r\n",
        "# 괄호, 중괄호로 끝\r\n",
        "def end_word_bracket(text):\r\n",
        "    if (str(text)[-1] in ['[', '(']):\r\n",
        "      return 1\r\n",
        "    else:\r\n",
        "      return 0\r\n",
        "\r\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '다', '로' ]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbHdqYRAqOlQ"
      },
      "source": [
        "train['get_words'] = train['content'].apply(lambda x:get_words(x))\r\n",
        "train['num_words']= train['get_words'].apply(lambda x:len(x))\r\n",
        "train['mean_word_len'] = train['get_words'].apply(lambda x: np.mean([len(w) for w in x]))\r\n",
        "train[\"num_chars\"] = train['content'].apply(lambda x: len(str(x)))\r\n",
        "train['noun'] = train['content'].apply(lambda x: fraction_noun(x))\r\n",
        "train['first_word_len']=train['get_words'].apply(lambda x: first_word_len(x))/train[\"num_chars\"]\r\n",
        "train['last_word_len']=train['get_words'].apply(lambda x: last_word_len(x))/train[\"num_chars\"]\r\n",
        "train['end_word_bracket'] = train['content'].apply(end_word_bracket)\r\n",
        "train = train.drop('get_words', axis = 1)\r\n",
        "\r\n",
        "test['get_words'] = test['content'].apply(lambda x:get_words(x))\r\n",
        "test['num_words']= test['get_words'].apply(lambda x:len(x))\r\n",
        "test['mean_word_len'] = test['get_words'].apply(lambda x: np.mean([len(w) for w in x]))\r\n",
        "test[\"num_chars\"] = test['content'].apply(lambda x: len(str(x)))\r\n",
        "test['noun'] = test['content'].apply(lambda x: fraction_noun(x))\r\n",
        "test['first_word_len'] = test['get_words'].apply(lambda x: first_word_len(x))/test[\"num_chars\"]\r\n",
        "test['last_word_len'] = test['get_words'].apply(lambda x: last_word_len(x))/test[\"num_chars\"]\r\n",
        "test['end_word_bracket'] = test['content'].apply(end_word_bracket)\r\n",
        "test = test.drop('get_words', axis = 1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEnBHquLW5wN"
      },
      "source": [
        "# 명사 토큰화 결과 중 title에 포함된 명사 개수\r\n",
        "\r\n",
        "train['same_in_title'] = 0\r\n",
        "\r\n",
        "for idx in range(len(train)):\r\n",
        "  num = 0\r\n",
        "  words_content = mecab.nouns(train.loc[idx, 'content'])\r\n",
        "\r\n",
        "  if idx == 0:  \r\n",
        "    words_title = mecab.nouns(train.loc[idx, 'title'])\r\n",
        "    for word in words_content:\r\n",
        "      if word in words_title:\r\n",
        "        num += 1\r\n",
        "\r\n",
        "  elif idx > 0:\r\n",
        "    if train.loc[idx, 'title'] == train.loc[idx-1, 'title']:\r\n",
        "      for word in words_content:\r\n",
        "        if word in words_title:\r\n",
        "          num += 1\r\n",
        "\r\n",
        "    elif train.loc[idx, 'title'] != train.loc[idx-1, 'title']:\r\n",
        "      words_title = mecab.nouns(train.loc[idx, 'title'])\r\n",
        "      for word in words_content:\r\n",
        "        if word in words_title:\r\n",
        "          num += 1\r\n",
        "\r\n",
        "  train.loc[idx, 'same_in_title'] = num\r\n",
        "\r\n",
        "train['same_in_title'] = train['same_in_title']/train['num_words']\r\n",
        " \r\n",
        "\r\n",
        "# 각 기사 내에서 문장의 ord를 비율로 바꾼 것\r\n",
        "# 예를 들어, 각 기사의 4개의 ord가 있다면 (1,2,3,4) -> (0.25, 0.5, 0.75, 1)로 변경\r\n",
        "\r\n",
        "count_per_news = train.groupby(['n_id'])['ord'].max()\r\n",
        "train['ord_changed'] = train['ord'].astype('float')\r\n",
        "for i in range(train.shape[0]):\r\n",
        "    train['ord_changed'][i] = train['ord'][i]/count_per_news[train['n_id'][i]]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhn8QCMAUxJP"
      },
      "source": [
        "# 명사 토큰화 결과 중 title에 포함된 명사 개수\r\n",
        "\r\n",
        "test['same_in_title'] = 0\r\n",
        "\r\n",
        "for idx in range(len(test)):\r\n",
        "  num = 0\r\n",
        "  words_content = mecab.nouns(test.loc[idx, 'content'])\r\n",
        "\r\n",
        "  if idx == 0:  \r\n",
        "    words_title = mecab.nouns(test.loc[idx, 'title'])\r\n",
        "    for word in words_content:\r\n",
        "      if word in words_title:\r\n",
        "        num += 1\r\n",
        "\r\n",
        "  elif idx > 0:\r\n",
        "    if test.loc[idx, 'title'] == test.loc[idx-1, 'title']:\r\n",
        "      for word in words_content:\r\n",
        "        if word in words_title:\r\n",
        "          num += 1\r\n",
        "\r\n",
        "    elif test.loc[idx, 'title'] != test.loc[idx-1, 'title']:\r\n",
        "      words_title = mecab.nouns(test.loc[idx, 'title'])\r\n",
        "      for word in words_content:\r\n",
        "        if word in words_title:\r\n",
        "          num += 1\r\n",
        "\r\n",
        "  test.loc[idx, 'same_in_title'] = num\r\n",
        "\r\n",
        "test['same_in_title'] = test['same_in_title']/test['num_words']\r\n",
        " \r\n",
        "\r\n",
        "# 각 기사 내에서 문장의 ord를 비율로 바꾼 것\r\n",
        "count_per_news_t = test.groupby(['n_id'])['ord'].max()\r\n",
        "test['ord_changed'] = test['ord'].astype('float')\r\n",
        "for i in range(test.shape[0]):\r\n",
        "    test['ord_changed'][i] = test['ord'][i]/count_per_news_t[test['n_id'][i]]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNqyvT0CVzV6"
      },
      "source": [
        "os.chdir('/content/Mecab-ko-for-Google-Colab/fastText-0.9.2')\r\n",
        "# Fasttext이 설치되어있는 경로로 변경\r\n",
        "\r\n",
        "def Mecab_Preprocessing(df):\r\n",
        "  tokenizer = Mecab() # setting tokenizer using Mecab\r\n",
        "  token_list = []\r\n",
        "  stopwords = ['에','을', '를', '이', '가', '은', '는', 'null'] #불용어 설정\r\n",
        "\r\n",
        "  for text in df['content']:\r\n",
        "    txt = re.sub('[^가-힣a-zA-Z1-9]',' ',text) # 한글, 영어, 대문자 외 제거\r\n",
        "    token = tokenizer.morphs(txt) # 품사 태깅\r\n",
        "    token = [t.lower() for t in token if t not in stopwords or type(t) != float]\r\n",
        "    token_list.append(token)\r\n",
        "\r\n",
        "  return token_list\r\n",
        "\r\n",
        "train['text']= Mecab_Preprocessing(train)\r\n",
        "test['text']= Mecab_Preprocessing(test)\r\n",
        "\r\n",
        "train['text']=[' '.join(s) for s in train['text']]\r\n",
        "test['text']=[' '.join(s) for s in test['text']]\r\n",
        "\r\n",
        "train_df = train.iloc[:,[-1,5]]\r\n",
        "train_df['info'] = ['__label__'+str(s) for s in train_df['info']] # 타겟변수 형식 변경 For Fasttext Modeliing\r\n",
        "\r\n",
        "test_df = test.iloc[:,-1]\r\n",
        "\r\n",
        "train_df.to_csv('train_df.txt',sep='\\t',index=False, header=False)\r\n",
        "train_df = pd.read_csv('train_df.txt', delimiter='\\t', header=None) # For Fasttext Modelling\r\n",
        "\r\n",
        "test_df.to_csv('test_df.txt',sep='\\t',index=False,header=False)\r\n",
        "test_df = pd.read_csv('test_df.txt',delimiter='\\t', header=None)  # For Fasttext Modelling"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix9lwjTcYIZJ"
      },
      "source": [
        "# Date 변수를 날짜 형식으로 변경\r\n",
        "train['date'] = pd.to_datetime(train['date'],format = '%Y%m%d')\r\n",
        "test['date'] = pd.to_datetime(test['date'],format = '%Y%m%d')\r\n",
        "\r\n",
        "# 해당 기사 발행 월을 계산(1-12)\r\n",
        "train['month'] = [s.month for s in train['date']]\r\n",
        "test['month'] = [s.month for s in test['date']]\r\n",
        "\r\n",
        "# 해당 기사 발행 주를 계산(1-52)\r\n",
        "train['week'] = [s.week for s in train['date']]\r\n",
        "test['week'] = [s.week for s in test['date']]\r\n",
        "\r\n",
        "# 각 본문와 동일한 기사 수를 추출 (Train)\r\n",
        "same_count = train.groupby('content')['ord'].count()\r\n",
        "train['count'] = 0\r\n",
        "for i,text in enumerate(train['content']):\r\n",
        "    train['count'][i] = same_count[text]\r\n",
        "\r\n",
        "# 각 본문와 동일한 기사 수를 추출 (Test)\r\n",
        "same_count_t = test.groupby('content')['ord'].count()\r\n",
        "test['count'] = 0\r\n",
        "for i,text in enumerate(test['content']):\r\n",
        "    test['count'][i] = same_count_t[text]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de5D4IGoYRhF"
      },
      "source": [
        "def Mecab_Preprocessing_title(df):\r\n",
        "  tokenizer = Mecab() # setting tokenizer using Mecab\r\n",
        "  token_list = []\r\n",
        "  stopwords = ['에','을', '를', '이', '가', '은', '는', 'null'] #불용어 설정\r\n",
        "\r\n",
        "  for text in df['title']:\r\n",
        "    txt = re.sub('[^가-힣a-zA-Z1-9]',' ',text) # 한글, 영어, 대문자 \r\n",
        "    token = tokenizer.morphs(txt) # 품사 태깅\r\n",
        "    token = [t.lower() for t in token if t not in stopwords or type(t) != float]\r\n",
        "    token_list.append(token)\r\n",
        "\r\n",
        "  return token_list\r\n",
        "\r\n",
        "train['title_t']= Mecab_Preprocessing_title(train)\r\n",
        "test['title_t']= Mecab_Preprocessing_title(test)\r\n",
        "\r\n",
        "# Glove Embedding 활용하여 기사 본문과 제목간의 임베딩 거리(유클리디안)\r\n",
        "def sent2vec(s):\r\n",
        "    M = []\r\n",
        "    count = 0\r\n",
        "    for w in s:\r\n",
        "        try:\r\n",
        "            M.append(glove[w])\r\n",
        "            count += 1\r\n",
        "        except:\r\n",
        "            continue\r\n",
        "    M = np.array(M)\r\n",
        "    v = M.sum(axis=0)\r\n",
        "    if type(v) != np.ndarray:\r\n",
        "        return np.zeros(100)\r\n",
        "        \r\n",
        "    # 단순 합으로 한 경우, 문장의 길이에 따라 다소 편향된 결과를 보여줌\r\n",
        "    # 따라서 일치된 token의 수로 나누어, 평균 값으로 계산\r\n",
        "    return v/count\r\n",
        "\r\n",
        "xtrain_text = np.array([sent2vec(x) for x in train['text']])\r\n",
        "xtrain_title =  np.array([sent2vec(x) for x in train['title_t']])\r\n",
        "xtest_text = np.array([sent2vec(x) for x in test['text']])\r\n",
        "xtest_title = np.array([sent2vec(x) for x in test['title_t']])\r\n",
        "\r\n",
        "train_sum = (xtrain_text-xtrain_title)**2\r\n",
        "train['distance'] = np.sqrt(train_sum.sum(axis = 1))\r\n",
        "\r\n",
        "test_sum = (xtest_text-xtest_title)**2\r\n",
        "test['distance'] = np.sqrt(test_sum.sum(axis = 1))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L6ztCnNYrvS"
      },
      "source": [
        "# 각각 진짜/가짜 기사에만 등장하는 단어 추출\r\n",
        "train_real=train.loc[train['info']==0,:]\r\n",
        "train_fake=train.loc[train['info']==1,:]\r\n",
        "\r\n",
        "train_real['tok_cont']=train_real['content'].apply(lambda x : mecab.morphs(x))\r\n",
        "train_fake['tok_cont']=train_fake['content'].apply(lambda x : mecab.morphs(x))\r\n",
        "\r\n",
        "sentences_real=train_real['tok_cont']\r\n",
        "words_real = np.hstack(sentences_real)\r\n",
        "vocab_real = Counter(words_real)\r\n",
        "\r\n",
        "sentences_fake=train_fake['tok_cont']\r\n",
        "words_fake = np.hstack(sentences_fake)\r\n",
        "vocab_fake = Counter(words_fake)\r\n",
        "\r\n",
        "only_real=vocab_real-vocab_fake  # 진짜 기사에만 등장하는 단어 리스트\r\n",
        "only_fake=vocab_fake-vocab_fake # 가짜 기사에만 등장하는 단어 리스트\r\n",
        "\r\n",
        "# 빈도 500이상의 단어만 사용  \r\n",
        "def only_list(only):\r\n",
        "    li=list(only)\r\n",
        "    cnt=[]\r\n",
        "    for i in li:\r\n",
        "        cnt.append(only[i])\r\n",
        "    df=pd.DataFrame({'list':li,'cnt': cnt})\r\n",
        "    df=df.loc[df['cnt']>500,:]         \r\n",
        "    return df\r\n",
        "\r\n",
        "real_df=only_list(only_real)\r\n",
        "fake_df=only_list(only_fake)\r\n",
        "\r\n",
        "real_list=real_df['list']\r\n",
        "fake_list=fake_df['list']\r\n",
        "def num_cnt(x,li):\r\n",
        "    a=0\r\n",
        "    for i in li:\r\n",
        "        a += x.count(i)\r\n",
        "    return a\r\n",
        "\r\n",
        "# 토큰화된 기사의 단어 중 각 리스트에 있는 단어 비율 변수 생성\r\n",
        "train['tok_cont']=train['content'].apply(lambda x : mecab.morphs(x))\r\n",
        "train['word_count_real'] = [num_cnt(s,real_list) for s in train['tok_cont']]\r\n",
        "train['word_count_fake'] = [num_cnt(s,fake_list) for s in train['tok_cont']]\r\n",
        "train['tok_len']=train['tok_cont'].apply(lambda x : len(x))\r\n",
        "train['real_word_rate']= train['word_count_real']/train['tok_len']\r\n",
        "train['fake_word_rate']= train['word_count_fake']/train['tok_len']\r\n",
        "\r\n",
        "test['tok_cont']=test['content'].apply(lambda x : mecab.morphs(x))\r\n",
        "test['tok_len']=test['tok_cont'].apply(lambda x: len(x))\r\n",
        "test['word_count_real'] = [num_cnt(s,real_list) for s in test['tok_cont']]\r\n",
        "test['word_count_fake'] = [num_cnt(s,fake_list) for s in test['tok_cont']]\r\n",
        "test['real_word_rate']= test['word_count_real']/test['tok_len']\r\n",
        "test['fake_word_rate']= test['word_count_fake']/test['tok_len']\r\n",
        "\r\n",
        "train=train.drop(['tok_cont','word_count_real','word_count_fake','tok_len'],axis=1)\r\n",
        "test=test.drop(['tok_cont','word_count_real','word_count_fake','tok_len'],axis=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFzBz0_vaxsl"
      },
      "source": [
        "# 앙상블 기법에 사용될 예측 모델링\r\n",
        "\r\n",
        "LR, SGD, RF, DT, Fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ly9h3GZa-uB"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXdvUkLOY6xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ffdb78-d829-414a-bdc9-1f98ff55a45a"
      },
      "source": [
        "# TFIDF vectorizer\r\n",
        "\r\n",
        "tfidf_vec = TfidfVectorizer(tokenizer=word_tokenize, stop_words=stopwords, ngram_range=(1, 3), min_df=100)\r\n",
        "train_tfidf = tfidf_vec.fit_transform(train['content'].values.tolist())\r\n",
        "test_tfidf = tfidf_vec.transform(test['content'].values.tolist())\r\n",
        "train_y = train['info']\r\n",
        "\r\n",
        "def runLR(train_X,train_y,test_X,test_y,test_X2):\r\n",
        "    model=LogisticRegression()\r\n",
        "    model.fit(train_X,train_y)\r\n",
        "    pred_test_y=model.predict_proba(test_X)\r\n",
        "    pred_test_y2=model.predict_proba(test_X2)\r\n",
        "    return pred_test_y, pred_test_y2, model\r\n",
        "\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "\r\n",
        "  # 학습 데이터와 검증 데이터 설정\r\n",
        "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "\r\n",
        "  # 학습 데이터로 모형 적합후, 검증 데이터의 예측 확률 계산\r\n",
        "    pred_val_y, pred_test_y, model = runLR(dev_X, dev_y, val_X, val_y,test_tfidf)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "  \r\n",
        "  # 검증 데이터 해당 Index에 예측 확률 입력\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "  \r\n",
        "  # Test 데이터에서 예측값 입력\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"tfidf_LR_0\"] = pred_train[:,0]\r\n",
        "test[\"tfidf_LR_0\"] = pred_full_test[:,0]\r\n",
        "\r\n",
        "# Count Vectorizer\r\n",
        "\r\n",
        "cvec_vec=CountVectorizer(tokenizer=word_tokenize, stop_words=stopwords, ngram_range=(1, 3), min_df=100)\r\n",
        "cvec_vec.fit(train['content'].values.tolist())\r\n",
        "train_cvec = cvec_vec.transform(train['content'].values.tolist())\r\n",
        "test_cvec = cvec_vec.transform(test['content'].values.tolist())\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_cvec[dev_index], train_cvec[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runLR(dev_X, dev_y, val_X, val_y,test_cvec)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"cvec_LR_0\"] = pred_train[:,0]\r\n",
        "test[\"cvec_LR_0\"] = pred_full_test[:,0]\r\n",
        "\r\n",
        "# Count Vectorizer (analyzer = 'char')\r\n",
        "\r\n",
        "cvec_char_vec = CountVectorizer(ngram_range=(1,7), analyzer='char',min_df=100)\r\n",
        "cvec_char_vec.fit(train['content'].values.tolist())\r\n",
        "train_cvec_char = cvec_char_vec.transform(train['content'].values.tolist())\r\n",
        "test_cvec_char = cvec_char_vec.transform(test['content'].values.tolist())\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop, axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_cvec_char[dev_index], train_cvec_char[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runLR(dev_X, dev_y, val_X, val_y,test_cvec_char)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"cvec_char_LR_0\"] = pred_train[:,0]\r\n",
        "test[\"cvec_char_LR_0\"] = pred_full_test[:,0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cv score :  0.08104863531382908\n",
            "Mean cv score :  0.07491818183541044\n",
            "Mean cv score :  0.040334034109110996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9iB3FpabF9D"
      },
      "source": [
        "## SGD "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9in8GKpfbMAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ae793a-9a12-4700-e672-7bbc11504849"
      },
      "source": [
        "def runSGD(train_X,train_y,test_X,test_y,test_X2):\r\n",
        "    model=SGDClassifier(loss='log')\r\n",
        "    model.fit(train_X,train_y)\r\n",
        "    pred_test_y=model.predict_proba(test_X)\r\n",
        "    pred_test_y2=model.predict_proba(test_X2)\r\n",
        "    return pred_test_y, pred_test_y2, model\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0], 2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runSGD(dev_X, dev_y, val_X, val_y,test_tfidf)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"tfidf_SGD_0\"] = pred_train[:,0]\r\n",
        "test[\"tfidf_SGD_0\"] = pred_full_test[:,0]\r\n",
        "\r\n",
        "# Count Vectorizer \r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_cvec[dev_index], train_cvec[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runSGD(dev_X, dev_y, val_X, val_y,test_cvec)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"cvec_SGD_0\"] = pred_train[:,0]\r\n",
        "test[\"cvec_SGD_0\"] = pred_full_test[:,0]\r\n",
        "\r\n",
        "# Count Vectorizer (analyzer = 'char')\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_cvec_char[dev_index], train_cvec_char[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runSGD(dev_X, dev_y, val_X, val_y,test_cvec_char)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"cvec_char_SGD_0\"] = pred_train[:,0]\r\n",
        "test[\"cvec_char_SGD_0\"] = pred_full_test[:,0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cv score :  0.12248979646457628\n",
            "Mean cv score :  0.09015134908653062\n",
            "Mean cv score :  0.04543385978912605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFdhLuy7blDD"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7lAKCLRbjtd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7c0733-6603-4c21-9290-879ae459fe3d"
      },
      "source": [
        "def runRF(train_X,train_y,test_X,test_y,test_X2):\r\n",
        "    model=RandomForestClassifier()\r\n",
        "    model.fit(train_X,train_y)\r\n",
        "    pred_test_y=model.predict_proba(test_X)\r\n",
        "    pred_test_y2=model.predict_proba(test_X2)\r\n",
        "    return pred_test_y, pred_test_y2, model\r\n",
        "\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runRF(dev_X, dev_y, val_X, val_y,test_tfidf)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"tfidf_RF_0\"] = pred_train[:,0]\r\n",
        "test[\"tfidf_RF_0\"] = pred_full_test[:,0]\r\n",
        "\r\n",
        "# Count Vectorizer\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_cvec[dev_index], train_cvec[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runRF(dev_X, dev_y, val_X, val_y,test_cvec)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"cvec_RF_0\"] = pred_train[:,0]\r\n",
        "test[\"cvec_RF_0\"] = pred_full_test[:,0]\r\n",
        "\r\n",
        "# Count Vectorizer (analyzer = 'char')\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_cvec_char[dev_index], train_cvec_char[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runRF(dev_X, dev_y, val_X, val_y,test_cvec_char)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"cvec_char_RF_0\"] = pred_train[:,0]\r\n",
        "test[\"cvec_char_RF_0\"] = pred_full_test[:,0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cv score :  0.07396055588520865\n",
            "Mean cv score :  0.08056932267018466\n",
            "Mean cv score :  0.03989879357166307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPO9UfKLcA32"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k_PUKUWb_ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2196d289-6a54-4724-d5e6-f9a3a2bdd955"
      },
      "source": [
        "def runDT(train_X,train_y,test_X,test_y,test_X2):\r\n",
        "    model=DecisionTreeClassifier()\r\n",
        "    model.fit(train_X,train_y)\r\n",
        "    pred_test_y=model.predict_proba(test_X)\r\n",
        "    pred_test_y2=model.predict_proba(test_X2)\r\n",
        "    return pred_test_y, pred_test_y2, model\r\n",
        "\r\n",
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_full_test = 0\r\n",
        "\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    pred_val_y, pred_test_y, model = runDT(dev_X, dev_y, val_X, val_y,test_tfidf)\r\n",
        "    pred_full_test = pred_full_test + pred_test_y\r\n",
        "    pred_train[val_index,:] = pred_val_y\r\n",
        "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\r\n",
        "print(\"Mean cv score : \", np.mean(cv_scores))\r\n",
        "pred_full_test = pred_full_test / 5.\r\n",
        "\r\n",
        "train[\"tfidf_DT_0\"] = pred_train[:,0]\r\n",
        "test[\"tfidf_DT_0\"] = pred_full_test[:,0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean cv score :  0.48713437796380943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUYirKpkcIFN"
      },
      "source": [
        "## Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "furvwlp40Xom",
        "outputId": "5c1ccd6c-2c66-4070-8775-d3922bb47004"
      },
      "source": [
        "# Mecab 설치 폴더 내 Fasttext 폴더 경로로 설정되어있음을 가정\r\n",
        "!pwd"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab/fastText-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoCwuq--cKf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317ec0e1-f574-4a9d-904f-3b36d5da95a6"
      },
      "source": [
        "cv_scores=[]\r\n",
        "cols_to_drop=['n_id',\t'date', 'title', 'content']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "cv = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "pred_train=np.zeros([train.shape[0],2])\r\n",
        "pred_test=np.zeros([test.shape[0],2])\r\n",
        "\r\n",
        "for dev_index, val_index in cv.split(train_X,train_y):\r\n",
        "    dev_X = train_df.iloc[dev_index,:]\r\n",
        "\r\n",
        "    # 현재 경로로 학습 데이터 저장\r\n",
        "    dev_X.to_csv('dev_X.txt',sep='\\t',index=False, header=False)\r\n",
        "    dev_X = pd.read_csv('dev_X.txt', delimiter='\\t', header=None)\r\n",
        "    dev_X.index = np.arange(dev_X.shape[0])\r\n",
        "    # 학습 데이터 모델 학습\r\n",
        "    !./fasttext supervised -input dev_X.txt -lr 1.0 -output model -dim 2\r\n",
        "    \r\n",
        "    # 검증 데이터 구성 및 예측\r\n",
        "    val_X = train_df.iloc[val_index,:]\r\n",
        "    val_X.to_csv('val_X.txt',sep='\\t',index=False, header=False)\r\n",
        "    val_X = pd.read_csv('val_X.txt', delimiter='\\t', header=None)\r\n",
        "    val_X.index = np.arange(val_X.shape[0])    \r\n",
        "    pred_test_y = !./fasttext predict-prob model.bin val_X.txt\r\n",
        "    pred0 = []; pred1 = []\r\n",
        "    for i in range(len(pred_test_y)):\r\n",
        "      if '__label__0' in pred_test_y[i]:\r\n",
        "        temp = float(pred_test_y[i].replace('__label__0','').strip())\r\n",
        "        if temp > 1:\r\n",
        "          pred0.append(1)\r\n",
        "          pred1.append(0)\r\n",
        "        elif temp < 0 :\r\n",
        "          pred0.append(0)\r\n",
        "          pred1.append(1)\r\n",
        "        else: \r\n",
        "          pred0.append(temp)\r\n",
        "          pred1.append(1-temp)\r\n",
        "      else: \r\n",
        "        temp = float(pred_test_y[i].replace('__label__1','').strip())\r\n",
        "        if temp > 1:\r\n",
        "          pred1.append(1)\r\n",
        "          pred0.append(0)\r\n",
        "        elif temp < 0 :\r\n",
        "          pred1.append(0)\r\n",
        "          pred0.append(1)\r\n",
        "        else: \r\n",
        "          pred1.append(temp)\r\n",
        "          pred0.append(1-temp)\r\n",
        "    \r\n",
        "    # 해당 위치에 예측값 적용\r\n",
        "    pred_train[val_index,0] = pred0\r\n",
        "    pred_train[val_index,1] = pred1\r\n",
        "     \r\n",
        "    # Test 데이터 셋에서 예측값 입력\r\n",
        "    pred_test_full = !./fasttext predict-prob model.bin test_df.txt\r\n",
        "    pred0 = []; pred1 = []\r\n",
        "\r\n",
        "    for i in range(len(pred_test_full)):\r\n",
        "      if '__label__0' in pred_test_full[i]:\r\n",
        "        temp = float(pred_test_full[i].replace('__label__0','').strip())\r\n",
        "        if temp > 1:\r\n",
        "          pred0.append(1)\r\n",
        "          pred1.append(0)\r\n",
        "        elif temp < 0 :\r\n",
        "          pred0.append(0)\r\n",
        "          pred1.append(1)\r\n",
        "        else: \r\n",
        "          pred0.append(temp)\r\n",
        "          pred1.append(1-temp)\r\n",
        "      else: \r\n",
        "        temp = float(pred_test_full[i].replace('__label__1','').strip())\r\n",
        "        if temp > 1:\r\n",
        "          pred1.append(1)\r\n",
        "          pred0.append(0)\r\n",
        "        elif temp < 0 :\r\n",
        "          pred1.append(0)\r\n",
        "          pred0.append(1)\r\n",
        "        else: \r\n",
        "          pred1.append(temp)\r\n",
        "          pred0.append(1-temp)    \r\n",
        "    \r\n",
        "    pred_test[:,0] =  pred_test[:,0]+pred0\r\n",
        "    pred_test[:,1] =  pred_test[:,1]+pred1\r\n",
        "\r\n",
        "pred_test = pred_test / 5.\r\n",
        "\r\n",
        "train[\"fxt_0\"] = pred_train[:,0]\r\n",
        "test[\"fxt_0\"] = pred_test[:,0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rRead 1M words\rRead 2M words\rRead 2M words\n",
            "Number of words:  36903\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread: 1065435 lr:  0.000000 avg.loss:  0.067167 ETA:   0h 0m 0s\n",
            "Read 2M words\n",
            "Number of words:  37091\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread: 1065339 lr:  0.000000 avg.loss:  0.059650 ETA:   0h 0m 0s\n",
            "Read 2M words\n",
            "Number of words:  36959\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread: 1066955 lr:  0.000000 avg.loss:  0.068242 ETA:   0h 0m 0s\n",
            "Read 2M words\n",
            "Number of words:  37086\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread:  960042 lr:  0.000000 avg.loss:  0.065898 ETA:   0h 0m 0s\n",
            "Read 2M words\n",
            "Number of words:  36875\n",
            "Number of labels: 2\n",
            "Progress: 100.0% words/sec/thread: 1065018 lr:  0.000000 avg.loss:  0.087040 ETA:   0h 0m 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6NrAxJUcXwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c17d0c1-ec6a-4a96-e80b-ac08a135ebc0"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['n_id', 'date', 'title', 'content', 'ord', 'info', 'num_words',\n",
              "       'mean_word_len', 'num_chars', 'noun', 'first_word_len', 'last_word_len',\n",
              "       'end_word_bracket', 'same_in_title', 'ord_changed', 'text', 'month',\n",
              "       'week', 'count', 'title_t', 'distance', 'real_word_rate',\n",
              "       'fake_word_rate', 'tfidf_LR_0', 'cvec_LR_0', 'cvec_char_LR_0',\n",
              "       'tfidf_SGD_0', 'cvec_SGD_0', 'cvec_char_SGD_0', 'tfidf_RF_0',\n",
              "       'cvec_RF_0', 'cvec_char_RF_0', 'tfidf_DT_0', 'fxt_0'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbyWotuXccn5"
      },
      "source": [
        "# 미사용 변수 제거\r\n",
        "\r\n",
        "train = train.drop(['ord','num_words'], axis = 1)\r\n",
        "test = test.drop(['ord','num_words'], axis = 1) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE8uxMI-czMZ"
      },
      "source": [
        "# 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPbDVS-ocwcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5930ca5e-dde7-4ba6-8450-dfee10b0c9c0"
      },
      "source": [
        "cols_to_drop = ['n_id','date','title','content','title_t','text']\r\n",
        "train_X = train.drop(cols_to_drop+['info'], axis=1)\r\n",
        "train_y=train['info']\r\n",
        "test_X = test.drop(cols_to_drop+['id'], axis=1)\r\n",
        "xgb_preds=[]\r\n",
        "\r\n",
        "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2020)\r\n",
        "\r\n",
        "for dev_index, val_index in kf.split(train_X):\r\n",
        "    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\r\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\r\n",
        "    dtrain = xgb.DMatrix(dev_X,label=dev_y)\r\n",
        "    dvalid = xgb.DMatrix(val_X, label=val_y)\r\n",
        "    watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\r\n",
        "\r\n",
        "    param = {}\r\n",
        "    param['objective'] = 'multi:softprob'\r\n",
        "    param['eta'] = 0.1\r\n",
        "    param['max_depth'] = 5\r\n",
        "    param['silent'] = 1\r\n",
        "    param['eval_metric'] = \"mlogloss\"\r\n",
        "    param['min_child_weight'] = 1\r\n",
        "    param['subsample'] = 0.8\r\n",
        "    param['colsample_bytree'] = 0.7\r\n",
        "    param['seed'] = 0\r\n",
        "    param['num_class']=2\r\n",
        "    param['tree_method'] = 'gpu_hist'\r\n",
        "\r\n",
        "    model = xgb.train(param, dtrain, 2000, watchlist, early_stopping_rounds=50, verbose_eval=20)\r\n",
        "\r\n",
        "    xgtest2 = xgb.DMatrix(test_X)\r\n",
        "    xgb_pred = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\r\n",
        "    xgb_preds.append(list(xgb_pred))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-mlogloss:0.600103\tvalid-mlogloss:0.600285\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[20]\ttrain-mlogloss:0.072301\tvalid-mlogloss:0.073926\n",
            "[40]\ttrain-mlogloss:0.018273\tvalid-mlogloss:0.020751\n",
            "[60]\ttrain-mlogloss:0.010274\tvalid-mlogloss:0.013311\n",
            "[80]\ttrain-mlogloss:0.0084\tvalid-mlogloss:0.012001\n",
            "[100]\ttrain-mlogloss:0.007003\tvalid-mlogloss:0.011329\n",
            "[120]\ttrain-mlogloss:0.005907\tvalid-mlogloss:0.011015\n",
            "[140]\ttrain-mlogloss:0.005005\tvalid-mlogloss:0.01075\n",
            "[160]\ttrain-mlogloss:0.004236\tvalid-mlogloss:0.010458\n",
            "[180]\ttrain-mlogloss:0.003608\tvalid-mlogloss:0.010276\n",
            "[200]\ttrain-mlogloss:0.003101\tvalid-mlogloss:0.010181\n",
            "[220]\ttrain-mlogloss:0.002692\tvalid-mlogloss:0.010142\n",
            "[240]\ttrain-mlogloss:0.002313\tvalid-mlogloss:0.010201\n",
            "[260]\ttrain-mlogloss:0.002034\tvalid-mlogloss:0.010209\n",
            "Stopping. Best iteration:\n",
            "[221]\ttrain-mlogloss:0.002677\tvalid-mlogloss:0.010132\n",
            "\n",
            "[0]\ttrain-mlogloss:0.600196\tvalid-mlogloss:0.600168\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[20]\ttrain-mlogloss:0.072537\tvalid-mlogloss:0.072945\n",
            "[40]\ttrain-mlogloss:0.018562\tvalid-mlogloss:0.019749\n",
            "[60]\ttrain-mlogloss:0.010515\tvalid-mlogloss:0.012542\n",
            "[80]\ttrain-mlogloss:0.008609\tvalid-mlogloss:0.011387\n",
            "[100]\ttrain-mlogloss:0.007069\tvalid-mlogloss:0.01085\n",
            "[120]\ttrain-mlogloss:0.005946\tvalid-mlogloss:0.010448\n",
            "[140]\ttrain-mlogloss:0.004976\tvalid-mlogloss:0.010304\n",
            "[160]\ttrain-mlogloss:0.004228\tvalid-mlogloss:0.010229\n",
            "[180]\ttrain-mlogloss:0.003624\tvalid-mlogloss:0.010108\n",
            "[200]\ttrain-mlogloss:0.00312\tvalid-mlogloss:0.010076\n",
            "[220]\ttrain-mlogloss:0.002698\tvalid-mlogloss:0.010014\n",
            "[240]\ttrain-mlogloss:0.002339\tvalid-mlogloss:0.01\n",
            "[260]\ttrain-mlogloss:0.002048\tvalid-mlogloss:0.010066\n",
            "Stopping. Best iteration:\n",
            "[227]\ttrain-mlogloss:0.002573\tvalid-mlogloss:0.009968\n",
            "\n",
            "[0]\ttrain-mlogloss:0.600159\tvalid-mlogloss:0.600038\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[20]\ttrain-mlogloss:0.072429\tvalid-mlogloss:0.072918\n",
            "[40]\ttrain-mlogloss:0.018337\tvalid-mlogloss:0.020062\n",
            "[60]\ttrain-mlogloss:0.010332\tvalid-mlogloss:0.012984\n",
            "[80]\ttrain-mlogloss:0.008397\tvalid-mlogloss:0.011889\n",
            "[100]\ttrain-mlogloss:0.006982\tvalid-mlogloss:0.011507\n",
            "[120]\ttrain-mlogloss:0.005804\tvalid-mlogloss:0.011234\n",
            "[140]\ttrain-mlogloss:0.004867\tvalid-mlogloss:0.0112\n",
            "[160]\ttrain-mlogloss:0.004132\tvalid-mlogloss:0.011197\n",
            "[180]\ttrain-mlogloss:0.00359\tvalid-mlogloss:0.011239\n",
            "Stopping. Best iteration:\n",
            "[146]\ttrain-mlogloss:0.004609\tvalid-mlogloss:0.011181\n",
            "\n",
            "[0]\ttrain-mlogloss:0.600108\tvalid-mlogloss:0.600286\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[20]\ttrain-mlogloss:0.072194\tvalid-mlogloss:0.074108\n",
            "[40]\ttrain-mlogloss:0.0182\tvalid-mlogloss:0.021103\n",
            "[60]\ttrain-mlogloss:0.010262\tvalid-mlogloss:0.013745\n",
            "[80]\ttrain-mlogloss:0.008407\tvalid-mlogloss:0.012307\n",
            "[100]\ttrain-mlogloss:0.006966\tvalid-mlogloss:0.011797\n",
            "[120]\ttrain-mlogloss:0.005841\tvalid-mlogloss:0.011469\n",
            "[140]\ttrain-mlogloss:0.004845\tvalid-mlogloss:0.01118\n",
            "[160]\ttrain-mlogloss:0.004037\tvalid-mlogloss:0.011164\n",
            "[180]\ttrain-mlogloss:0.003423\tvalid-mlogloss:0.011123\n",
            "[200]\ttrain-mlogloss:0.002951\tvalid-mlogloss:0.011116\n",
            "[220]\ttrain-mlogloss:0.002573\tvalid-mlogloss:0.011103\n",
            "[240]\ttrain-mlogloss:0.002222\tvalid-mlogloss:0.011145\n",
            "[260]\ttrain-mlogloss:0.001939\tvalid-mlogloss:0.011175\n",
            "Stopping. Best iteration:\n",
            "[226]\ttrain-mlogloss:0.002446\tvalid-mlogloss:0.011071\n",
            "\n",
            "[0]\ttrain-mlogloss:0.600073\tvalid-mlogloss:0.600428\n",
            "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-mlogloss hasn't improved in 50 rounds.\n",
            "[20]\ttrain-mlogloss:0.071862\tvalid-mlogloss:0.075237\n",
            "[40]\ttrain-mlogloss:0.017911\tvalid-mlogloss:0.022375\n",
            "[60]\ttrain-mlogloss:0.010013\tvalid-mlogloss:0.015109\n",
            "[80]\ttrain-mlogloss:0.008106\tvalid-mlogloss:0.013851\n",
            "[100]\ttrain-mlogloss:0.006791\tvalid-mlogloss:0.013232\n",
            "[120]\ttrain-mlogloss:0.005724\tvalid-mlogloss:0.012807\n",
            "[140]\ttrain-mlogloss:0.004877\tvalid-mlogloss:0.012553\n",
            "[160]\ttrain-mlogloss:0.004143\tvalid-mlogloss:0.012358\n",
            "[180]\ttrain-mlogloss:0.003441\tvalid-mlogloss:0.012192\n",
            "[200]\ttrain-mlogloss:0.003004\tvalid-mlogloss:0.012146\n",
            "[220]\ttrain-mlogloss:0.00256\tvalid-mlogloss:0.012127\n",
            "[240]\ttrain-mlogloss:0.002214\tvalid-mlogloss:0.012227\n",
            "Stopping. Best iteration:\n",
            "[207]\ttrain-mlogloss:0.002824\tvalid-mlogloss:0.012094\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cby22SXc5vd"
      },
      "source": [
        "for i in range(len(xgb_preds[0])):\r\n",
        "    sum=0\r\n",
        "    for j in range(5):\r\n",
        "        sum+=xgb_preds[j][i]    \r\n",
        "    if(i==0):\r\n",
        "        preds=sum/5\r\n",
        "    else:\r\n",
        "        preds=np.vstack([preds,sum/5])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_sXfgEbc8Qo"
      },
      "source": [
        "preds=pd.DataFrame(preds)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTnMfCXwc_OY"
      },
      "source": [
        "sample_submission.loc[:,'info'] = np.where(preds.iloc[:,1]> 0.5, 1, 0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jw-ArLldA4U"
      },
      "source": [
        "# Test의 기사 본문 중 학습 데이터의 가짜 뉴스와 일치하는 것 \r\n",
        "\r\n",
        "train_unique_ad_sentence = train.query('info == \"1\"')['content'].unique()\r\n",
        "test_unique_sentence = test['content'].unique()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdvi2oQmdOQB"
      },
      "source": [
        "test_content = test['content'].values\r\n",
        "\r\n",
        "for idx, sent in enumerate(test_content) : #Test 데이터에 있는 모든 content들에 대하여\r\n",
        "\r\n",
        "    if sent in train_unique_ad_sentence: # Train 데이터의 광고성 문구와 같은지 비교\r\n",
        "        sample_submission['info'].iloc[idx] = 1 # 같으면 1"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW3c_j6yd8QH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d649aee3-33f9-4768-ef05-41a674803a33"
      },
      "source": [
        "print(time.time() - start)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2279.5649194717407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKvDp_DQd_q_"
      },
      "source": [
        "# 제출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYyIaiawdbp_"
      },
      "source": [
        "sample_submission.to_csv('/content/submission.csv', index = False) "
      ],
      "execution_count": 38,
      "outputs": []
    }
  ]
}